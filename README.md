
<p align="center">

  <h2 align="center"><strong>LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?</strong></h2>

<div align="center">
<h5>
<em>Maoyuan Ye<sup>1</sup>, Jing Zhang<sup>1 â€ </sup>, Juhua Liu<sup>1 â€ </sup>, Bo Du<sup>1</sup>, Dacheng Tao<sup>2</sup> </em>
    <br><br>
       	<sup>1</sup> School of Computer Science, Wuhan University, China<br/>
        <sup>2</sup>  College of Computing & Data Science, Nanyang Technological University, Singapore<br/> 
</h5>
<h5>
<sup>â€ </sup> Corresponding author
</h5>
</div>


<h5 align="center">
<a href="https://huggingface.co/datasets/MiliLab/LogicOCR"><img src="https://img.shields.io/badge/%20HuggingFace-LogicOCR-FFD43B.svg?logo=huggingface"></a>
</h5>






# ğŸŒ Intro



# ğŸ”¥ Update



# ğŸ”¨ Evaluation

---

## ğŸ“ 0. Clone the Repository & Download Data

Clone Repository:

```bash
git clone https://github.com/MiliLab/LogicOCR
cd LogicOCR
```

---

## ğŸ§± 1. Prepare the Runtime Environment


## â–¶ï¸ 2. Run Evaluation



# â­ Citation

If you find LogicOCR helpful, please consider giving this repo a â­ and citing:

```latex

```
